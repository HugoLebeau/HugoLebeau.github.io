<!DOCTYPE html>

<html>

<head>
<meta charset="utf-8" />
<title>Hugo Lebeau</title>
</head>

<body>

<h1>Hugo Lebeau</h1>

<hr />

<div class="container" style="overflow: hidden">
<div class="image" style="float: left; margin-right: 10px"><img src="me_200x150.jpg" alt="Hugo Lebeau" /></div>
<div class="text"><b><big>Postdoctoral Researcher, Inria (ENS Lyon)</big></b><br />
<a href="https://team.inria.fr/ockham/">OCKHAM Team</a><br />
<br />
<b>Office</b>: M7 1H32<br />
<b>Mail</b>: <a href="mailto:hugo.lebeau@inria.fr">hugo.lebeau@inria.fr</a><br />
<br />
<a href="Lebeau_CV.pdf">CV</a> &ensp; <a href="https://scholar.google.com/citations?user=atRIpOIAAAAJ">Google Scholar</a> &ensp; <a href="https://orcid.org/0009-0001-8317-3876">ORCID</a> &ensp; <a href="https://github.com/HugoLebeau">GitHub</a> &ensp; <a href="https://www.linkedin.com/in/hugo-lebeau/">LinkedIn</a>
</div>
</div>

<h2>Research Topics</h2>
I am broadly interested in <b>statistical and algorithmic aspects</b> of <b>machine learning</b> from <b>high-dimensional data</b>, notably through the study of <b>random matrix and tensor models</b>. In particular, this includes,
<ul>
<li>spiked random matrix and tensor models,</li>
<li>random tensors and their low-rank approximations,</li>
<li>theoretical study of complex clustering tasks (multi-view, time-varying),</li>
<li>learning with memory constraints, compressive learning.</li>
</ul>
Random matrix theory is a powerful tool to study <i>practical</i> statistical settings of the big data era.

<h2>Publications</h2>
<ul>
<li>JMLR &ndash; <b>A Random Matrix Approach to Low-Multilinear-Rank Tensor Approximation</b>, Hugo Lebeau, Florent Chatelain, Romain Couillet [<a href="https://jmlr.org/papers/v26/24-0193.html">article</a>]</li>
<li>IEEE Signal Processing Letters &ndash; <b>Asymptotic Gaussian Fluctuations of Eigenvectors in Spectral Clustering</b>, Hugo Lebeau, Florent Chatelain, Romain Couillet [<a href="https://doi.org/10.1109/LSP.2024.3422886">article (IEEE)</a>][<a href="https://arxiv.org/abs/2402.12302">article (arXiv)</a>][<a href="https://github.com/HugoLebeau/asymptotic_fluctuations_spectral_clustering">code</a>]</li>
</ul>
<ul>
<li>ICLR 2024 &ndash; <b>Performance Gaps in Multi-view Clustering under the Nested Matrix-Tensor Model</b>, Hugo Lebeau, Mohamed El Amine Seddik, José Henrique de Morais Goulart [<a href="https://openreview.net/forum?id=ILqA09Oeq2">article</a>][<a href="https://github.com/HugoLebeau/nested_matrix-tensor">code</a>]</li>
<li>ICML 2022 &ndash; <b>A Random Matrix Analysis of Data Stream Clustering: Coping With Limited Memory Resources</b>, Hugo Lebeau, Romain Couillet, Florent Chatelain [<a href="https://proceedings.mlr.press/v162/lebeau22a.html">article</a>][<a href="https://github.com/HugoLebeau/online_learning">code</a>][<a href="https://slideslive.com/38983621">video</a>]</li>
</ul>
<ul>
<li>GRETSI 2025 &ndash; <b>Performance of Rank-One Tensor Approximation on Incomplete Data</b>, Hugo Lebeau [<a href="https://arxiv.org/abs/2504.07818">article</a>]</li>
<li>GRETSI 2023 &ndash; <b>HOSVD Tronquée : Analyse d'une Approximation Tensorielle Rapide</b>, Hugo Lebeau, Romain Couillet, Florent Chatelain [<a href="https://gretsi.fr/data/colloque/pdf/2023_lebeau1060.pdf">article</a>]</li>
<li>GRETSI 2022 &ndash; <b>Une analyse par matrices aléatoires du clustering en ligne : comprendre l’impact des limitations en mémoire</b>, Hugo Lebeau, Romain Couillet, Florent Chatelain [<a href="https://gretsi.fr/data/colloque/pdf/2022_lebeau757.pdf">article</a>]</li>
</ul>

<h2>Ph.D. Thesis</h2>
My Ph.D. manuscript <i>Random Matrix and Tensor Models for Large Data Processing</i> is available <a href="thesisLebeauH.pdf">here</a>.
<ul>
<li>Want to know what this is about? Check the abstract on page 3!</li>
<li>Want to know more? Great! The introduction (16 pages) will give you a broad overview of the main challenges.</li>
<li>Still interested? Feel free to dive into the chapters. Chapter 2 may be a prerequisite if you want to fully understand the following ones.</li>
</ul>

<h2>Teaching</h2>
<p>I currently take part in the following courses as teaching assistant.
<ul>
<li>ENS Paris-Saclay, Master MVA &mdash; <i>Random Matrix Theory and Machine Learning</i>.</li>
<li>ENS Lyon, M1 &mdash; <i>Statistics</i>.</li>
</ul>
See my <a href="Lebeau_CV.pdf">CV</a> for a full list of my previous teachings.</p>
<p>I have written (in French) a short reflection on my first two years of teaching. It is available <a href="apprendre_a_enseigner.pdf">here</a>.</p>

</body>

</html>
